{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "965aa5c5-54ee-4a27-8770-8131a32f5039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "# Turn off warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "126a826f-824e-44d5-8904-5e87f2949423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# URL of the dataset\n",
    "url = 'https://archive.ics.uci.edu/static/public/222/bank+marketing.zip'\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "\n",
    "# Write the file to a local path\n",
    "with open('bank_marketing.zip', 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "print(\"Dataset downloaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a903aa20-2d11-4bef-8e92-2adc6f0751f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset unpacked successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Unpack the dataset\n",
    "with zipfile.ZipFile('bank_marketing.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "\n",
    "print(\"Dataset unpacked successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9363118f-e61c-40f1-87ec-438b22bfa269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age           job  marital  education  balance housing  contact  day month  \\\n",
      "0   58    management  married   tertiary     2143     yes  unknown    5   may   \n",
      "1   44    technician   single  secondary       29     yes  unknown    5   may   \n",
      "2   33  entrepreneur  married  secondary        2     yes  unknown    5   may   \n",
      "3   47   blue-collar  married    unknown     1506     yes  unknown    5   may   \n",
      "4   33       unknown   single    unknown        1      no  unknown    5   may   \n",
      "\n",
      "   duration  campaign  pdays  previous poutcome   y  \n",
      "0       261         1     -1         0  unknown  no  \n",
      "1       151         1     -1         0  unknown  no  \n",
      "2        76         1     -1         0  unknown  no  \n",
      "3        92         1     -1         0  unknown  no  \n",
      "4       198         1     -1         0  unknown  no  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('bank/bank-full.csv', sep=';')\n",
    "\n",
    "# Select the specified columns\n",
    "columns = ['age', 'job', 'marital', 'education', 'balance', 'housing', \n",
    "           'contact', 'day', 'month', 'duration', 'campaign', 'pdays', \n",
    "           'previous', 'poutcome', 'y']\n",
    "data = data[columns]\n",
    "\n",
    "# Display the first few rows\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca37296-ae43-43b6-b0dd-99776768babc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each feature:\n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "balance      0\n",
      "housing      0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n",
      "No missing values found.\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the selected features\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Display the missing values\n",
    "print(\"Missing values in each feature:\")\n",
    "print(missing_values)\n",
    "\n",
    "# If no missing values, display a message\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"No missing values found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecdfa1d-d4fd-45d0-a2ea-ca33f194f3f8",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "What is the most frequent observation (mode) for the column education?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cc289a6-e59d-40fe-acc9-1a76325010fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent observation (mode) for the column 'education' is: secondary\n"
     ]
    }
   ],
   "source": [
    "# Find the mode (most frequent observation) for the 'education' column\n",
    "education_mode = data['education'].mode()[0]\n",
    "\n",
    "# Display the mode\n",
    "print(f\"The most frequent observation (mode) for the column 'education' is: {education_mode}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33428352-2025-4666-a0de-182aa7a1592c",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Create the correlation matrix for the numerical features of your dataset. In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "\n",
    "What are the two features that have the biggest correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b549dfbd-9b3c-4886-ac1e-3d1a6235643d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  balance  day  duration  campaign  pdays  previous\n",
      "0   58     2143    5       261         1     -1         0\n",
      "1   44       29    5       151         1     -1         0\n",
      "2   33        2    5        76         1     -1         0\n",
      "3   47     1506    5        92         1     -1         0\n",
      "4   33        1    5       198         1     -1         0\n"
     ]
    }
   ],
   "source": [
    "# Select numerical features\n",
    "numerical_features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Create a DataFrame with only numerical columns\n",
    "numerical_data = data[numerical_features]\n",
    "\n",
    "# Display the first few rows to confirm\n",
    "print(numerical_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c9e4f26-33e0-45c8-a075-b8d627fa7109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n",
      "               age   balance       day  duration  campaign     pdays  previous\n",
      "age       1.000000  0.097783 -0.009120 -0.004648  0.004760 -0.023758  0.001288\n",
      "balance   0.097783  1.000000  0.004503  0.021560 -0.014578  0.003435  0.016674\n",
      "day      -0.009120  0.004503  1.000000 -0.030206  0.162490 -0.093044 -0.051710\n",
      "duration -0.004648  0.021560 -0.030206  1.000000 -0.084570 -0.001565  0.001203\n",
      "campaign  0.004760 -0.014578  0.162490 -0.084570  1.000000 -0.088628 -0.032855\n",
      "pdays    -0.023758  0.003435 -0.093044 -0.001565 -0.088628  1.000000  0.454820\n",
      "previous  0.001288  0.016674 -0.051710  0.001203 -0.032855  0.454820  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Compute the correlation matrix\n",
    "correlation_matrix = numerical_data.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67833774-576d-4a08-b145-ff50dd5278b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two features with the highest correlation are: previous and pdays\n"
     ]
    }
   ],
   "source": [
    "# Unstack the correlation matrix to find the pair of features with the highest correlation\n",
    "correlation_pairs = correlation_matrix.unstack()\n",
    "\n",
    "# Sort the correlation pairs by their absolute value in descending order\n",
    "sorted_pairs = correlation_pairs.abs().sort_values(ascending=False)\n",
    "\n",
    "# Exclude the diagonal (i.e., correlation of a feature with itself)\n",
    "sorted_pairs = sorted_pairs[sorted_pairs < 1]\n",
    "\n",
    "# Get the pair with the highest correlation\n",
    "most_correlated_pair = sorted_pairs.idxmax()\n",
    "\n",
    "# Display the most correlated pair and their correlation value\n",
    "print(f\"The two features with the highest correlation are: {most_correlated_pair[0]} and {most_correlated_pair[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b716450-3f3c-4107-9ab5-b77e0ec48c30",
   "metadata": {},
   "source": [
    "## Target encoding\n",
    "Now we want to encode the y variable.\n",
    "Let's replace the values yes/no with 1/0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4177c4d8-7284-46bb-afce-f9c72b25413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace 'yes' with 1 and 'no' with 0 in the 'y' column\n",
    "data['y'] = data['y'].replace({'yes': 1, 'no': 0})\n",
    "\n",
    "# Confirm the transformation\n",
    "print(data['y'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3778a7ab-36d4-4428-9426-726f421e6350",
   "metadata": {},
   "source": [
    "## Split the data\n",
    "Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "Use Scikit-Learn for that (the train_test_split function) and set the seed to 42.\n",
    "Make sure that the target value y is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47cdf372-31dd-40f0-a83d-e2b57aa8c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = data.drop('y', axis=1)  # Remove the target column from the features\n",
    "y = data['y']  # Target column\n",
    "\n",
    "# Split the data: 60% train, 20% validation, 20% test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e02987f1-08d7-43da-8ae4-969a183e2cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 job  marital  education housing   contact month poutcome\n",
      "20326     technician   single   tertiary     yes  cellular   aug  unknown\n",
      "24301   entrepreneur  married  secondary     yes  cellular   nov  unknown\n",
      "38618    blue-collar  married  secondary     yes  cellular   may  unknown\n",
      "18909      housemaid  married    primary      no  cellular   aug  unknown\n",
      "23081  self-employed  married   tertiary      no  cellular   aug  unknown\n"
     ]
    }
   ],
   "source": [
    "# List of categorical features\n",
    "categorical_features = ['job', 'marital', 'education', 'housing', 'contact', 'month', 'poutcome']\n",
    "\n",
    "# Slice the training and validation sets to keep only the categorical features\n",
    "X_train_categorical = X_train[categorical_features]\n",
    "X_val_categorical = X_val[categorical_features]\n",
    "\n",
    "# Display the first few rows to confirm\n",
    "print(X_train_categorical.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87b07a70-701b-462e-8da0-df64cf456cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contact=cellular', 'contact=telephone', 'contact=unknown', 'education=primary', 'education=secondary', 'education=tertiary', 'education=unknown', 'housing=no', 'housing=yes', 'job=admin.', 'job=blue-collar', 'job=entrepreneur', 'job=housemaid', 'job=management', 'job=retired', 'job=self-employed', 'job=services', 'job=student', 'job=technician', 'job=unemployed', 'job=unknown', 'marital=divorced', 'marital=married', 'marital=single', 'month=apr', 'month=aug', 'month=dec', 'month=feb', 'month=jan', 'month=jul', 'month=jun', 'month=mar', 'month=may', 'month=nov', 'month=oct', 'month=sep', 'poutcome=failure', 'poutcome=other', 'poutcome=success', 'poutcome=unknown']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the training and validation sets into lists of dictionaries\n",
    "train_dicts = X_train_categorical.to_dict(orient='records')\n",
    "val_dicts = X_val_categorical.to_dict(orient='records')\n",
    "\n",
    "# Initialize the DictVectorizer\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# Fit the DictVectorizer on the training data and transform both training and validation data\n",
    "X_train_encoded = dv.fit_transform(train_dicts)\n",
    "X_val_encoded = dv.transform(val_dicts)\n",
    "\n",
    "# Display the feature names created by the DictVectorizer (optional)\n",
    "print(dv.feature_names_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadf7c62-28de-453b-8694-56b413f4e7f2",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Calculate the mutual information score between y and other categorical variables in the dataset. Use the training set only.\n",
    "Round the scores to 2 decimals using round(score, 2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9696e189-7899-409f-8eae-5178685c4506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information Scores between y and categorical features:\n",
      "contact=cellular: 0.01\n",
      "contact=telephone: 0.0\n",
      "contact=unknown: 0.01\n",
      "education=primary: 0.0\n",
      "education=secondary: 0.0\n",
      "education=tertiary: 0.0\n",
      "education=unknown: 0.0\n",
      "housing=no: 0.01\n",
      "housing=yes: 0.02\n",
      "job=admin.: 0.0\n",
      "job=blue-collar: 0.0\n",
      "job=entrepreneur: 0.0\n",
      "job=housemaid: 0.0\n",
      "job=management: 0.0\n",
      "job=retired: 0.0\n",
      "job=self-employed: 0.0\n",
      "job=services: 0.0\n",
      "job=student: 0.0\n",
      "job=technician: 0.0\n",
      "job=unemployed: 0.0\n",
      "job=unknown: 0.0\n",
      "marital=divorced: 0.0\n",
      "marital=married: 0.01\n",
      "marital=single: 0.01\n",
      "month=apr: 0.0\n",
      "month=aug: 0.0\n",
      "month=dec: 0.0\n",
      "month=feb: 0.0\n",
      "month=jan: 0.0\n",
      "month=jul: 0.0\n",
      "month=jun: 0.0\n",
      "month=mar: 0.01\n",
      "month=may: 0.01\n",
      "month=nov: 0.0\n",
      "month=oct: 0.0\n",
      "month=sep: 0.01\n",
      "poutcome=failure: 0.0\n",
      "poutcome=other: 0.0\n",
      "poutcome=success: 0.03\n",
      "poutcome=unknown: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Calculate mutual information for the categorical features in the training data\n",
    "mi_scores = mutual_info_classif(X_train_encoded, y_train)\n",
    "\n",
    "# Round the scores to 2 decimal places\n",
    "mi_scores_rounded = [round(score, 2) for score in mi_scores]\n",
    "\n",
    "# Map the scores back to their respective features\n",
    "mi_scores_dict = dict(zip(dv.feature_names_, mi_scores_rounded))\n",
    "\n",
    "# Display the mutual information scores for all features\n",
    "print(\"Mutual Information Scores between y and categorical features:\")\n",
    "for feature, score in mi_scores_dict.items():\n",
    "    print(f\"{feature}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53a01980-4954-4256-9308-682960145117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature with the highest mutual information score is: poutcome=success with a score of 0.03\n"
     ]
    }
   ],
   "source": [
    "# Find the feature with the highest mutual information score\n",
    "max_mi_feature = max(mi_scores_dict, key=mi_scores_dict.get)\n",
    "max_mi_score = mi_scores_dict[max_mi_feature]\n",
    "\n",
    "# Display the result\n",
    "print(f\"The feature with the highest mutual information score is: {max_mi_feature} with a score of {max_mi_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4774bbdf-4c2d-4e56-9a45-cca625ed83a5",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Now let's train a logistic regression.\n",
    "Remember that we have several categorical variables in the dataset. Include them using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "894a5abc-df69-4428-aba0-0ed0439c23c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contact=cellular', 'contact=telephone', 'contact=unknown', 'education=primary', 'education=secondary', 'education=tertiary', 'education=unknown', 'housing=no', 'housing=yes', 'job=admin.', 'job=blue-collar', 'job=entrepreneur', 'job=housemaid', 'job=management', 'job=retired', 'job=self-employed', 'job=services', 'job=student', 'job=technician', 'job=unemployed', 'job=unknown', 'marital=divorced', 'marital=married', 'marital=single', 'month=apr', 'month=aug', 'month=dec', 'month=feb', 'month=jan', 'month=jul', 'month=jun', 'month=mar', 'month=may', 'month=nov', 'month=oct', 'month=sep', 'poutcome=failure', 'poutcome=other', 'poutcome=success', 'poutcome=unknown']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Convert the training and validation sets into lists of dictionaries\n",
    "train_dicts = X_train_categorical.to_dict(orient='records')\n",
    "val_dicts = X_val_categorical.to_dict(orient='records')\n",
    "\n",
    "# Initialize DictVectorizer\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# Fit the DictVectorizer on the training data and transform both training and validation data\n",
    "X_train_encoded = dv.fit_transform(train_dicts)\n",
    "X_val_encoded = dv.transform(val_dicts)\n",
    "\n",
    "# Check the encoded feature names (optional)\n",
    "print(dv.feature_names_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f57754e3-0a4d-4af5-8cad-7b164911fc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Logistic Regression model with specified parameters\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "# Train (fit) the model on the training set\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Predict the target values on the validation set\n",
    "y_pred = model.predict(X_val_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c0889fa-9f21-402f-8e01-ac9c40903de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy on the validation set\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "# Round the accuracy to 2 decimal places\n",
    "accuracy_rounded = round(accuracy, 2)\n",
    "\n",
    "# Display the accuracy\n",
    "print(f\"Accuracy on the validation set: {accuracy_rounded}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb63238-cdef-43ee-990d-5e32cbc50b84",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Let's find the least useful feature using the feature elimination technique.\n",
    "Train a model with all these features (using the same parameters as in Q4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82a0c45a-919c-4521-aeb0-c60894284d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Train the baseline model with all features\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Calculate the baseline accuracy on the validation set\n",
    "y_pred = model.predict(X_val_encoded)\n",
    "baseline_accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "# Display the baseline accuracy\n",
    "print(f\"Baseline Accuracy: {round(baseline_accuracy, 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19c912c8-c433-47e0-85f3-f2db70eb1c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: age, Accuracy Difference: -0.0114\n",
      "Feature: balance, Accuracy Difference: -0.0112\n",
      "Feature: marital, Accuracy Difference: -0.0118\n",
      "Feature: previous, Accuracy Difference: -0.0118\n"
     ]
    }
   ],
   "source": [
    "# List of features to exclude\n",
    "features_to_test = ['age', 'balance', 'marital', 'previous']\n",
    "\n",
    "# Initialize a dictionary to store accuracy differences\n",
    "accuracy_differences = {}\n",
    "\n",
    "# Loop through each feature in the specified list\n",
    "for feature in features_to_test:\n",
    "    # Drop the feature from the original training and validation sets\n",
    "    X_train_dropped = X_train.drop(columns=[feature])\n",
    "    X_val_dropped = X_val.drop(columns=[feature])\n",
    "    \n",
    "    # Convert to dictionaries and re-encode using DictVectorizer\n",
    "    train_dicts_dropped = X_train_dropped.to_dict(orient='records')\n",
    "    val_dicts_dropped = X_val_dropped.to_dict(orient='records')\n",
    "    \n",
    "    # Re-encode the remaining features\n",
    "    X_train_encoded_dropped = dv.fit_transform(train_dicts_dropped)\n",
    "    X_val_encoded_dropped = dv.transform(val_dicts_dropped)\n",
    "    \n",
    "    # Train a new model without the dropped feature\n",
    "    model.fit(X_train_encoded_dropped, y_train)\n",
    "    \n",
    "    # Predict on the validation set without the feature\n",
    "    y_pred_dropped = model.predict(X_val_encoded_dropped)\n",
    "    \n",
    "    # Calculate the accuracy without the feature\n",
    "    dropped_accuracy = accuracy_score(y_val, y_pred_dropped)\n",
    "    \n",
    "    # Calculate the difference from the baseline accuracy\n",
    "    accuracy_diff = baseline_accuracy - dropped_accuracy\n",
    "    \n",
    "    # Store the result in the dictionary\n",
    "    accuracy_differences[feature] = accuracy_diff\n",
    "\n",
    "# Display the accuracy differences\n",
    "for feature, diff in accuracy_differences.items():\n",
    "    print(f\"Feature: {feature}, Accuracy Difference: {round(diff, 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0455800-39b7-4bbf-844e-ff55e52721f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The least useful feature (from the given options) is: marital with a difference of -0.0118\n"
     ]
    }
   ],
   "source": [
    "# Find the feature with the smallest difference\n",
    "least_useful_feature = min(accuracy_differences, key=accuracy_differences.get)\n",
    "smallest_difference = accuracy_differences[least_useful_feature]\n",
    "\n",
    "# Display the least useful feature and the smallest difference\n",
    "print(f\"The least useful feature (from the given options) is: {least_useful_feature} with a difference of {round(smallest_difference, 4)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3fc792-667d-4ab0-ad3c-88912b8a5294",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "Now let's train a regularized logistic regression.\n",
    "Let's try the following values of the parameter C: [0.01, 0.1, 1, 10, 100].\n",
    "Train models using all the features as in Q4.\n",
    "Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "Which of these C leads to the best accuracy on the validation set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71a6b4ab-023d-4ba5-8457-c1d3b65740ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for each C value:\n",
      "C = 0.01: Accuracy = 0.8881\n",
      "C = 0.1: Accuracy = 0.8898\n",
      "C = 1: Accuracy = 0.8896\n",
      "C = 10: Accuracy = 0.8894\n",
      "C = 100: Accuracy = 0.8894\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of C values to try\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Dictionary to store accuracy for each C value\n",
    "accuracy_results = {}\n",
    "\n",
    "# Loop through each value of C, train the model, and evaluate accuracy\n",
    "for C in C_values:\n",
    "    # Initialize the logistic regression model with the given C\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    \n",
    "    # Predict the target values on the validation set\n",
    "    y_pred = model.predict(X_val_encoded)\n",
    "    \n",
    "    # Calculate the accuracy on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    \n",
    "    # Round the accuracy to 3 decimal places\n",
    "    accuracy_rounded = round(accuracy, 4)\n",
    "    \n",
    "    # Store the accuracy in the dictionary\n",
    "    accuracy_results[C] = accuracy_rounded\n",
    "\n",
    "# Display the accuracy for each value of C\n",
    "print(\"Accuracy for each C value:\")\n",
    "for C, acc in accuracy_results.items():\n",
    "    print(f\"C = {C}: Accuracy = {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29d7e945-be99-4881-92aa-00a4bfeb2e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The best C value is: 0.1 with an accuracy of 0.8898\n"
     ]
    }
   ],
   "source": [
    "# Find the C value with the highest accuracy\n",
    "best_C = max(accuracy_results, key=accuracy_results.get)\n",
    "best_accuracy = accuracy_results[best_C]\n",
    "\n",
    "# Display the best C value and its corresponding accuracy\n",
    "print(f\"\\nThe best C value is: {best_C} with an accuracy of {best_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a97b324-4e59-4449-b2f1-f6003c8b9752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
